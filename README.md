# SVbyEye Pipeline

The SVbyEye pipeline automates the selection, alignment, and visualization of segmental duplication (SD) pairs using the [SVbyEye](https://github.com/daewoooo/SVbyEye) R package. It is designed for comparative genomics teams that require reproducible, well-documented summaries of SD structure across assemblies and reference genomes.

## Key Capabilities

- Assigns stable SD identifiers and derives helper metadata (sizes, optional liftover context) without altering your curated list.
- Validates precomputed PAF alignments (generated upstream with minimap2 or an equivalent tool) and records provenance in a manifest.
- Renders publication-ready plots with SVbyEye directly from the supplied PAF files.
- Produces an HTML report that consolidates summary statistics and plot artifacts for rapid review.
- Provides an end-to-end Snakemake workflow with checkpoints, logging, and automated testing hooks.

## Requirements

- **Operating system:** Linux or macOS.
- **Core tools:** [Snakemake](https://snakemake.readthedocs.io/), Python ≥3.9, and R ≥4.2 with the SVbyEye dependencies.
- **Optional:** `minimap2` (or your preferred aligner) for generating the PAF files consumed by this workflow, plus `conda`/`mamba` for environment management.

The `setup.sh` script and the `install_svbyeye*.R` helpers provide reference installation steps for common environments.

## Getting Started

1. **Clone the repository** and create the reproducible Conda environment (mamba recommended for speed):
   ```bash
   mamba env create -f environment.yml     # or: conda env create -f environment.yml
   conda activate svbyeye_pipeline
   Rscript install_svbyeye_github.R
   ```
2. **Prepare input data**
   - Place a tab-delimited SD callset at `data/sd_calls.tsv`. The table must include at least `Sample`, `Haplotype`, `SD1_original`, and `SD2_original`. Optional columns such as `SD*_T2T`, `SD*_has_exon`, and `Gene_names` enable richer annotations.
   - Generate minimap2 PAF alignments for every SD pair that will be visualized (ensure `-c --eqx` or equivalent so the `cg` tag is present) and store them under `data/alignments/` or your preferred directory.
3. **Configure the analysis** by editing `config.yaml`. At minimum update `sd_calls`, set the `alignments` block to match your directory/pattern, and review the metadata/visualization parameters.
4. **Dry-run the workflow** to verify rule resolution:
   ```bash
   snakemake -n
   ```
5. **Execute the pipeline** once the configuration is validated (the environment above provides every dependency):
   ```bash
   snakemake --cores 4
   ```
   _Tip:_ Keep the `svbyeye_pipeline` environment activated whenever you run Snakemake or auxiliary scripts so that the bundled R/Python binaries are used.
6. **Review the outputs** in the directory specified by `output_dir` (default: `results/`). Key artifacts include:
   - `sd_table.tsv`: SD metadata table with assigned identifiers and derived sizes.
   - `sd_summary.txt`: quick QC readout listing SD IDs and T2T availability.
   - `alignment_manifest.tsv`: validation log tying SD IDs to the backing PAF paths.
   - `data/alignments/*.paf` (or your configured directory): pairwise alignments supplied to the workflow.
   - `plots/*.png` (and optionally `.pdf`): visual summaries generated by SVbyEye.
   - `summary_report.html`: consolidated statistics and figures.

## Configuration Overview

`config.yaml` governs pipeline behavior. Important sections include:

- **Input definition:** `sd_calls` declares the SD callset, while `alignments.dir`/`alignments.filename_pattern` describe where the precomputed PAF files live.
- **Visualization:** `svbyeye` options configure binning, highlighting, and output format. `add_gene_annotations` toggles support for future gene overlays.
- **Execution resources:** `threads` and `memory` dictionaries specify resource hints for Snakemake rules.

All configuration options are documented inline within `config.yaml` for ease of maintenance.

## Workflow Summary

The Snakefile orchestrates the following stages:

1. **SD preparation (`prepare_sd_table`)** – assigns SD IDs and derives helper metadata while preserving every row in the callset.
2. **Alignment manifest (`prepare_alignment_manifest`)** – validates that every SD has a corresponding PAF file and records the file paths.
3. **Visualization (`visualize_sd`)** – creates SVbyEye plots for each SD using the supplied PAF alignments.
4. **Reporting (`generate_report`)** – collates metadata and plots into an HTML summary.

Auxiliary rules support data cleanup, configuration checks, and collection of generated plots. The `scripts/create_test_data.py` helper now builds synthetic PAF fixtures that mimic the minimap2 output required by SVbyEye, so no FASTA assets are bundled with the repository.

## Testing and Continuous Integration

A GitHub Actions workflow (`.github/workflows/test-pipeline.yml`) demonstrates how to run the pipeline in a continuous integration context. Triggering the workflow executes the full Snakemake pipeline on bundled test data and uploads the resulting artifacts. Adapt the workflow to mirror your production environment or to validate changes before deployment.

## Contributing

- Follow the code style documented in the repository (PEP 8 for Python, tidyverse style for R) and keep comments concise, descriptive, and oriented toward scientific interpretation.
- Update tests and documentation when modifying workflow logic or configuration interfaces.
- Use descriptive commit messages and Pull Request descriptions that summarize both functional changes and scientific context.

## Support

For questions about SVbyEye plotting semantics, consult the upstream [SVbyEye documentation](https://github.com/daewoooo/SVbyEye). Issues specific to this pipeline can be raised via the repository issue tracker.
